{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate new folder with clean pn jsons and fiterted images\n",
    "from papermage import Document\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import json\n",
    "from cord19_plus.utils import image_from_box\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import groupby\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import glob\n",
    "from multiprocessing import Manager\n",
    "from tqdm import tqdm\n",
    "import pymupdf\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Logging-Level auf einen Wert setzen, der h√∂her ist als CRITICAL\n",
    "logger.setLevel(logging.CRITICAL + 1)\n",
    "\n",
    "from cord19_plus.data_model.helpers.caption import (get_caption_for_box,\n",
    "                                                    get_cleaned_captions,\n",
    "                                                    text_matches_pattern)\n",
    "\n",
    "\n",
    "#logger = logging.getLogger(__name__)\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "# Define the paths\n",
    "input_folder = '/workspaces/CORD19_Plus/data/rel_pdfs_out'\n",
    "input_folder = \"/workspaces/CORD19_Plus/data/clean/pub_json2/*.json\"\n",
    "\n",
    "input_pdf_path = \"/workspaces/CORD19_Plus/data/rel_pdfs\"\n",
    "output_pub = \"/workspaces/CORD19_Plus/data/clean/pub_json2\"\n",
    "output_tab_img = \"/workspaces/CORD19_Plus/data/clean/tab_img2\"\n",
    "output_pub_pdf = \"/workspaces/CORD19_Plus/data/clean/pub_pdf3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pub_jsons = glob.glob(os.path.join(input_folder, '*.json'))\n",
    "pub_jsons = sorted(glob.glob(input_folder))[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_tables(doc):\n",
    "    tables = doc.tables\n",
    "    healthy_tables = []\n",
    "\n",
    "    for table in tables:\n",
    "        \n",
    "        t_caps_cleaned = get_cleaned_captions(doc)\n",
    "        \n",
    "        t_caption = get_caption_for_box(box=table.boxes[0],\n",
    "                                        captions=doc.captions,\n",
    "                                        caption_ids=t_caps_cleaned[\"tables\"])\n",
    "        \n",
    "        if text_matches_pattern(t_caption, \"tables\") or text_matches_pattern(table.text, \"tables\"):\n",
    "            healthy_tables.append(table)\n",
    "\n",
    "    return healthy_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clean_tables(path, shared_dict):\n",
    "\n",
    "    #check if output already exists\n",
    "    file_name = path.split(\"/\")[-1]\n",
    "    #if os.path.exists(f\"{output_pub}/{file_name}\"):\n",
    "    #    return\n",
    "\n",
    "    try:\n",
    "        with open(path, \"r\") as f:\n",
    "            doc_json = json.load(f)\n",
    "            current_doc = Document.from_json(doc_json)\n",
    "        \n",
    "\n",
    "        with shared_dict['lock']:  # Ensure shared access is thread-safe\n",
    "            shared_dict['all_cnt'] += len(current_doc.tables)\n",
    "            shared_dict['all_tables'] += [{path.split(\"/\")[-1].replace(\".json\", \"\") : len(current_doc.tables)}]\n",
    "        \n",
    "            \n",
    "        current_doc.tables.entities = fix_tables(current_doc)\n",
    "        \n",
    "        with shared_dict['lock']:\n",
    "            shared_dict['healthy_cnt'] += len(current_doc.tables)\n",
    "            shared_dict['healthy_tables'] += [{path.split(\"/\")[-1].replace(\".json\", \"\") : len(current_doc.tables)}]\n",
    "\n",
    "        \n",
    "        with open(f\"{output_pub}/{file_name}\", \"w\") as _f:\n",
    "            json.dump(current_doc.to_json(), _f)\n",
    "        \n",
    "        #save images\n",
    "        entities = list(current_doc.get_layer(\"tables\"))\n",
    "        \n",
    "        entities = sorted(entities, key=lambda x: x.boxes[0].page)\n",
    "        for key, group in groupby(entities, key=lambda x: x.boxes[0].page):\n",
    "            for table_id, table in enumerate(list(group)):\n",
    "                box = table.boxes[0]\n",
    "                page = box.page\n",
    "                doc_id = file_name.split(\".\")[0]\n",
    "                scale = pymupdf.Matrix(2, 2)\n",
    "\n",
    "                im_path = output_tab_img / Path(f\"{doc_id}_{page}_{table_id}.png\")\n",
    "\n",
    "                try:\n",
    "                    shutil.copy(f\"{input_pdf_path}/{doc_id}.pdf\", f\"{output_pub_pdf}/{doc_id}.pdf\")\n",
    "                    image_from_box(box, f\"{input_pdf_path}/{doc_id}.pdf\", im_path, scale)\n",
    "                    logger.info(\n",
    "                        f\"For {doc_id} : {input_pdf_path}/{doc_id}.pdf exported table nr {table_id} from page {box.page} to {im_path}\"\n",
    "                    )\n",
    "                except ValueError as e:\n",
    "                    logger.error(\n",
    "                        f\"Failed for {doc_id} table {table_id} from page {box.page}, pdf path {input_pdf_path}/{doc_id}.pdf. Because of ValueError: {e}\"\n",
    "                    )\n",
    "                    continue\n",
    "                except pymupdf.FileNotFoundError as f:\n",
    "                    logger.error(f\"PDF file not found for {doc_id},{input_pdf_path}/{doc_id}.pdf \")\n",
    "    except:\n",
    "        print(f\"something wrong with {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_workers = 10\n",
    "\n",
    "all_cnt = None\n",
    "healthy_cnt = None\n",
    "all_tables = None\n",
    "healthy_tables = None\n",
    "\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "\n",
    "    with Manager() as manager:\n",
    "        shared_dict = manager.dict()\n",
    "        shared_dict['all_cnt'] = 0  # Shared counter for all tables\n",
    "        shared_dict['healthy_cnt'] = 0  # Shared counter for healthy tables\n",
    "        shared_dict['lock'] = manager.Lock()  # Lock to synchronize access\n",
    "\n",
    "        shared_dict['healthy_tables'] = []\n",
    "        shared_dict['all_tables'] = []    \n",
    "\n",
    "        futures = [\n",
    "            executor.submit(save_clean_tables, path, shared_dict)\n",
    "            for path in pub_jsons[:len(pub_jsons)]\n",
    "        ]\n",
    "\n",
    "        # Use tqdm for showing progress\n",
    "        for _ in tqdm(futures, total=len(futures), desc=\"Total PDFs\", leave=True):\n",
    "            _.result()  # This will propagate any exceptions raised during processing\n",
    "\n",
    "        all_cnt = shared_dict['all_cnt']\n",
    "        healthy_cnt = shared_dict['healthy_cnt']\n",
    "        all_tables = shared_dict['all_tables']\n",
    "        healthy_tables = shared_dict['healthy_tables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tables = {k: v for d in all_tables for k, v in d.items()}\n",
    "healthy_tables  = {k: v for d in healthy_tables for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.DataFrame(list(all_tables.items()), columns=[\"docno\", \"all_tables\"])\n",
    "healthy_df = pd.DataFrame(list(healthy_tables.items()), columns=[\"docno\", \"healthy_tables\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df = pd.merge(all_df, healthy_df, on='docno', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_df = pd.read_csv(\"/workspaces/CORD19_Plus/data/qrels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "merged_df = pd.merge(qrels_df, table_df, on='docno', how='left')\n",
    "\n",
    "merged_df[['all_tables', 'healthy_tables']] = merged_df[['all_tables', 'healthy_tables']].fillna(0)\n",
    "\n",
    "# Group by 'qid' and sum 'all_tables' and 'healthy_tables'\n",
    "grouped = merged_df.groupby('qid')[['all_tables', 'healthy_tables']].sum().reset_index()\n",
    "\n",
    "# Sort by 'qid' for better visualization\n",
    "grouped = grouped.sort_values('qid')\n",
    "\n",
    "# Melt the DataFrame to long format for seaborn\n",
    "melted = grouped.melt(id_vars='qid', \n",
    "                      value_vars=['all_tables', 'healthy_tables'],\n",
    "                      var_name='Table Type', \n",
    "                      value_name='Count')\n",
    "\n",
    "# Set the style of the visualization\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Create a barplot\n",
    "sns.barplot(x='qid', y='Count', hue='Table Type', data=melted)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Number of Tables and Healthy Tables per QID', fontsize=16)\n",
    "plt.xlabel('QID', fontsize=14)\n",
    "plt.ylabel('Number of Tables', fontsize=14)\n",
    "\n",
    "# Customize the legend\n",
    "plt.legend(title='Table Type', fontsize=12, title_fontsize=12)\n",
    "\n",
    "# Improve layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
