{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to download 1000 random pdfs from CORD19 and analyse failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from cord19_plus.downloadpdf.downloaders import Index, Status, IndexRow\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "import pickle\n",
    "from urllib.parse import urlparse\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "base_path = Path(\"\")  # set path to 1000 random records\n",
    "index_path = base_path / Path(\"index.jsonl\")\n",
    "download_dir_path = base_path / Path(\"pdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the index\n",
    "index = Index.from_jsonl(index_path, download_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of downloaded PDFs\n",
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion for filtering the index obj by status\n",
    "def filter_by_status(index: Index, status: Union[Status, list[Status]]) -> list[IndexRow]:\n",
    "    if not isinstance(status, list):\n",
    "        status = [status]\n",
    "\n",
    "    status = set([s.value for s in status])\n",
    "    return [entry for doi, entry in index.items() if entry.status in status]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded = filter_by_status(index, Status.DOWNLOADED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(downloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_downloaded = filter_by_status(\n",
    "    index, [Status.NOT_IN_OPENALEX, Status.NOT_OPEN_ACCESS, Status.RATE_LIMIT_ERROR, Status.UNAVAILABLE]\n",
    ")\n",
    "print(len(not_downloaded))\n",
    "reasons = [Status(entry.status) for entry in not_downloaded]\n",
    "counts = dict(Counter(reasons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts statuses of not_downloaded pdfs\n",
    "# most common reason is Status.UNAVAILABLE\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unavailable = [entry for entry in not_downloaded if entry.status == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unavailable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.pie(\n",
    "    [9 / 1000, 477 / 1000, 145 / 1000, 6 / 1000, 363 / 1000],\n",
    "    (0, 0, 0, 0, 0),\n",
    "    [\"Connection Error\", \"Downloaded\", \"Not Open Access\", \"Not in OpenAlex\", \"Not a PDF\"],\n",
    "    startangle=20,\n",
    "    autopct=\"%1.1f%%\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recrawled all unavailable urls to find last available url using script find_last_url.py\n",
    "- 1 failed because of connection problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dir = base_path / Path(\"pickles\")\n",
    "responses = []\n",
    "for file in pickle_dir.iterdir():\n",
    "    responses.append(pickle.load(open(file, \"rb\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse urls of last history url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_last_url = []\n",
    "for r in responses:\n",
    "    if len(r.history) > 0:\n",
    "        p_url = urlparse(r.history[-1].url)\n",
    "    else:\n",
    "        p_url = urlparse(r.url)\n",
    "    parsed_last_url.append(p_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract netlocs to count website fails\n",
    "netlocs = [pr.netloc for pr in parsed_last_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_unavailable = Counter(netlocs).most_common(10)\n",
    "print(most_common_unavailable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse status codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_codes = [r.status_code for r in responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 403 Forbidden\n",
    "# 200 OK\n",
    "# 404 Not Found\n",
    "status_counts = Counter(status_codes).most_common()\n",
    "print(status_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.pie([s[1] for s in status_counts], labels=[f\"HTTP({str(s[0])})\" for s in status_counts], autopct=\"%1.1f%%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by status codes\n",
    "status_dict = {}\n",
    "for r in responses:\n",
    "    if r.status_code not in status_dict.keys():\n",
    "        status_dict[r.status_code] = []\n",
    "\n",
    "    status_dict[r.status_code].append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse urls\n",
    "status_dict_url_parse = {}\n",
    "for key in status_dict:\n",
    "    for r in status_dict[key]:\n",
    "        if key not in status_dict_url_parse.keys():\n",
    "            status_dict_url_parse[key] = []\n",
    "        p_url = urlparse(r.url)\n",
    "        status_dict_url_parse[key].append(p_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in status_dict_url_parse:\n",
    "    plt.figure(dpi=150)\n",
    "    counts = Counter([r.netloc for r in status_dict_url_parse[key]]).most_common(10)\n",
    "    print(key, counts)\n",
    "    plt.bar([c[0] for c in counts], [c[1] for c in counts])\n",
    "    plt.xticks(rotation=50, ha=\"right\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
